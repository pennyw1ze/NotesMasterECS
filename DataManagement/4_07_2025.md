### Timestamp
Concurrency based on timestamp. We define a total order based on the order in which the schedule are received from the scheduler.
The scheduler timestamps the transactions in increasing order and execute transactions following timestamps order.

For each element X we keep the following data:
- **rts(X)** next X reader;
- **wts(X)** next X writer;
- **wts-c(X)** last X writer;
- **cb(X)** a bit that is false if the transaction who wrote X lastly has not committed yet.

The system manages 2 temporal axes, **physical** and **logical** time.
The phisical time is when an action of a transaction occurs in a schedule, the logical time is the "transaction order" in which they appear in the schedule itself.
To see if transactions are compatible with each other we must have non conflicting order between phisical and logical time i.e. no transaction that has greater phisical time must have lower logical time or viceversa.
When we find a conflict, the conflicting transaction is aborted and executed again later with a new timestamp.

Also with timestamp based method we do not avoid the possibility of deadlock.
- Timestamp-based method is superior when transactions are “read-only”, or when concurrent transactions rarely write the same elements;
- 2PL is superior when the number of conflicts is high because the probability of rollback is higher in the timestamp-based method;

### Transactions in SQL
We have 3 anomalies in SQL:
- Dirty read:
- Non repeatable read: when a transaction read same element twice;
- Phantom read: this happens when we operate on a range of tuples, and in the same time another transaction operates on that tuples. Then our range operation will be disturbed. We need to range lock the elements;

---

### Pages and records
The dimension of a page is usually the dimension of a block.
A **page** has an address and is constituted by a set of slots. A **slot** is a memory space that contains a record of a relation.

A **file** is a collection of pages. Usually all records in a page belongs to the same relation.
Usually a file organizatio supports the following operations:
- **insert**;
- **delete**;
- **update**;
- **read**;
- **scan**;

# File organization

## Simple
### Heap
In a heap file organization the file representing the relation contains a set of pages, each with a set of records. There is **no order criteria** in this structure.
We can imagine the structure of heap files as a linked lists of pages, where there are 2 lists: the first contains the full pages, and the second contains the free pages.

Pages of the same relation are associated into **buckets**.
A set of fields of the relation is choosen as **search key**.
To search for a relation, we can imagine the heap file as an array, and using search key hashed to index the relations stored in the file.

##### Costs
Where B is the number of pages of the file;
- **Insertion**: O(1);
- **Deletion**: O(1);
- **Update**: O(1);
- **Scan**: O(B);
- Equality selection:

### Sorted
**Search key**: set of attributes on which the relation is sorted.
Since the pages in the file are sorted we have clever ways to search for an element.
- **Scan**: O(B): Still have to look into every page;
- **Equality selection**: means searching for an element, so in the avarage case is (Olog(B));
- **Insertion**: O(B) we have to sort all the array;
- **Deletion**: O(B);


### Hashed file
- **Scan:** O(B);
- **Equality selection:** O(1);
- **Range selection:** O(B);
- **Insertion:** O(1);
- **Deletion:** O(1);

### Sorting 
Now we wander if a user wants to receive an ordered result of a query or for whatever other reason, we might need to have ordered data stored.
But how do we order data ?
It is not as simple as it looks because data are stored in secondary storage so accessing data is slow. We need more efficient algorithms. We might do this job with the help of a special element: **the buffer**.
We want to do sorting based on pages, not on records!
We could run merge sort on our buffer that stores pages 2 at a time and merge them.
In this way we will pay $2\times B\times (log_2(B) +1)$.
In this way our buffer is only using 3 frames, 2 to store inputs and 1 to store merged output.

How can we **reduce the number of passes**?
Well that happens if we increase the number of buffers. In this way, we can merge more block in the same step. This will increase the base of the logarithm of B in the cost equation.

So the new cost will be:$$2\times B \times (log_{F-1}B)$$
## Index
An index is a method that given a property is able to find data with that property as value.
The property can be any, not just the key of the relation.
The index have several properites.

#### Organization
We can have:
- Sorted index;
- Tree based index;
- Hash-based index;

### Data entry structure
The data entry could be:
- Data records;
- Pair (k,r) where r is a reference to a data with search key k;
- Pair (k,r-list) where r-list is a list of references to data records with search key k;

### Clustering
An index is **clustering** (strongly clustering) when its data entries are sored with the same order as data records.
We say that an index is **weakly clustering** if 