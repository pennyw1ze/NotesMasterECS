# Classical Planning
In classical planning, actions are deterministic. Generalizing we'll have a domain with $n$ possible states, representing all the possible valid configurations.
Actions are (finite) entities that allow the agents to change the world.

These 3 parts ==(state space, action space, transition function) are what defines the domain.==

> [!WARNING]
>In classical planning, effects are always predictable once we do certain actions, and this limits the use cases. (e.g. we cannot model a dice throwing).

The problem consist in a tuple $<D, s_0, G, \alpha>$:
- $D$ = Domain  ($D= <S, A, \delta>$)
- $s_0$ = Initial State
- $G$ = Goal set
- $\alpha : S \rightarrow 2^A$ =  Function that, given a state, returns 
## Reachability
Given a tuple $<D, s_0, G, \alpha>$, find a sequence of actions $\pi = (a_1, ... a_l)$ such that:
- $s_{i+1} = \delta(s_i, a_i) \ \forall i = 0, ..., l-1$
- $a_i \in \alpha(s_i-1)$
- $a_l \in G$
If it satisfies the requirements above, $\pi$ is called a (solution) plan for the problem $P$. If we represent states as nodes, and actions as edges, we can model reachability as a path finding problem in graph!
Uninformed search is when we don't take advantage on knowledge of the entire domain.
```
bool Search(D, s_0, G){
	set Marked = {s_0}
	set Frontier = {s_0} // open set, contains set of states while we search
	while Frontier not empty{
		state i = Frontier.pop()
		if i in G{
			return True
		}
		for a in alpha(i){
			j = delta(i, a)
			if j not in Marked{
				Frontier.push(j)
				Marked.push(j)
			}
		}		
	}
	return False
}
```

> [!NOTE]
> By using a Marked set, we are creating a kind of tree.

Given this algorithm, which only studies the decisional problem of reachability, can be modified to add a plan, so that in the case we find a Goal State we have also associated the solution plan.