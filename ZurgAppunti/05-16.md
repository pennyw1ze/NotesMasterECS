# Present and Future of Networking
## Software-Defined Networking
Why? 2020 AWS outage took down big portion of internet. Also, 2021 outage of Facebook because of BGP updates.
We need to change to a more "modern network", more adaptable to traffic patterns and user demads. **Unification of different standards!** No more different programs for different routers/switches. Programmability/automation impossible, traditional network is CLI set up.

**Software Defined Networking** detaches the control plane from the data plane, *centralizing the controller*. It's vendor agnostic. Data plane is responsible for only forwarding packets, only thing it does it check the match-action table. Data-plane operation should be done, so that it doesn't redirect every packet to controller (bottlenecking).

Everything is done with OpenFlow protocol, through messages that can be synchronous and asyncrhonous. Some challenges is the fact that there is a SPoF (controller is not scalable). There is also a **lack of standards**, and also centralization means less privacy.

## Programmable Data Planes
This isn't really programmability though, since the packet processing pipeline on the switch is untouched. We are trying to create ASICs since they offer better performance than full-software (Intel Tofino) to get programmability. Programmable switches are programmed via the P4 language.
Some benefits include: Improved performance, hardware independence (although P4 flavours need an arch file which is architecture-dependent), it enforces QoS and security. It's still a new technology, so many network operators do not have expertise. It may also have new bugs.

Training of neural network to program P4 switches, for Intrusion, anomaly, DDoS detection.

To offload the machine learning computation cost we can train separately, and then install it on the switch. this limits the possibilities! We may use online learning, sampling some packets to train neural network.
It uses **CARAVAN** system. It's based on:
- **Labeling agent**
- **Model validator**
- **Model trainer**
## Open Projects
### Efficient ML
How to deploy efficiently ML algorithms in data planes? 
- New feature partser: packet/flow based
### Neurosymbolic AI
- Hybrid paradigm combining NN with symbolic knowledge and reasonin (lkogic, rules, knowledge graphs, discrete search)
Idea is to create a generalizable intelligent with is data-efficient
Idea is to add the reasoning (and so explainability) into machine learning, which are usually seen as black boxes.

How good are already-existing LLMs for these goals?
# Machine Learning Security
Use of ML techniques (DL especially) for security application has been increasing for
- **multimedia forensics**
- biometrics-based authentication
- ...
Idea is we are basing our life more and more to ML. So we need to better consider its security. ML is used for classification. It can be fooled, with enough well crafted noise.
Even a single pixel is enough to break some Convolutional Neural networks, even though som expertise on it is required.
Training and test data follow usually same statistics, and also same noice. We need to create a noise independent modell. Attacker may be aware of the ML tool and is able to watch parts of the training process

Idea ios to intrroduce an error by adding random noise, but to perform a tailored attack.
- **White box attack**: Attacker has knowledge to create the adversarial perturbation
- **Black box attack** requires the attacker to explore the model behaviours, probing it.
![[Pasted image 20250516123732.png]]How to desing Deep Learning?
**Adversary-aware retraining**: We mayu want to regenerate elements closer to a class
There isn't a standard solution, its an open-problem

Backdoors attacks are serious threats! Injecting attributes-noise into training data so that a thing can be recognized as whatever the attacker wants.
On deep neural networks there is also the possibility of poisoning some neurons in hiddne layers.

For full-control data training an attacker needs to have stealthiness at test time. It also needs high attack success rate, and it should also be difficult to remove.


To defend against that, there needs tro be a high scrutiny level on the training set and the labels to detect. Alice may also need to monitor the training process (has high costs)
## Taxonomy of Backdoor Attacks
![[Pasted image 20250516124531.png]]
Based on trigger types:
- Single image trigger
- Static vs adaptive vs randomized patterns
- Visible vs unvisible trigger
- Noise addition
#### Properties
Stealthiness
- Training data shouldd be innocuous
Unobscrtusiveness:
- should be working without any trigger
#### removing backdoors
Pruining: Backdoors oftern rely on dormant nodes, so we prune inactive nodes  (while trying to not affect model performance).

Other possibilities is to watermark a verified neural netowork. (basically is using  the trigger as a unique watermark)