# Organization of Index
### Sorted Indexes
Suppose we have a file (which contains one relation). If for example we want to store the file with all records sorted. Suppose we have 1000 pages and we want to search for a particular record. We need $\log_2(B = 1000) = 10$ entries for a binary search. 
The idea of **sorted index** is to create another sorted file, with the pages that contain data entries which has $<value, pointer>$ tuples (with $pointer$ being $<page.id, slot.id>$, which are sorted on the interested attributes (it's a **clustered index**). The number of pages will be proportional to $2/ \text{\# attributes}$, since now every data entry has only two values. $\frac{B}{N}$ With $B$ number of pages.
A search now costs $\log_2(\frac{B}{N}) + 1 = \log_2(B) - \log_2(N) +1 = 6$, with the $+1$ being for the page access on the entry found. (the advantage finds itself in range queries too).
- **Drawback**: Adding/deleting a value in the data file means that we need to also add an entry to the index page *to keep it up-to-date*. It's a sort-of investment. Inserting a data entry in a dense index could be the same as inserting a data entry in the data file, or we can use *local overflow tables*, hoping they don't grow too much (most common one).

This means we have a **clustering sorted index**, which can be primary of secondary (depending on the search key chosen). Even here we may have sparse and \[strongly/weakly] dense.

Sometimes, if the index is sufficiently small, we can **keep it in the buffer**, which would make the cost go even lower to just 1.
We can do some optimization to find just the existance, in the case of the dense index.

All of this works with *range queries*, since we are clustered.

#### An application for unclustered sorted index
Could be useful for when, for a given attribute, there is an associated foreign key vincolo to another relation. We may want to order the original relation for that keyed attribute, while we may want to order the other one based on a more elegant ordering on the second relation.
- Movie(title, year, lenght, studioname)
- Studio(name, address, president)
We may want to order the Movie relation based on title, while we create the index and we order it over the Studio name.
#### Clustered File Organization
Not about clustered indexes!
we can decide to store the two relations in a clustered file, where we include in each Studio record all the Movie records of movies made by that studio
![[Pasted image 20250519140448.png]]
kind of a Document-based database.
> [!WARNING]
> It's a data admin thing to ask the DBMS to manually create indexes and clustered files. Generally, the DBMS automatically creates an index based on the primary key.


### Tree-based
We can infinitely build sparse sorted indexes on the dense indexes, adding levels. (stamo a'npazzÃ¬) Basically we are recursively constructing a sparse index until we have just 1 page.
The number of levels will depend on how many data entries will fit in a page

Has **very good performance** on search, insertion and deletion.
Typical structure of an intermediate node (root too) is as follows

|       |       |       |       |     |           |       |       |
| ----- | ----- | ----- | ----- | --- | --------- | ----- | ----- |
| $P_0$ | $K_1$ | $P_1$ | $K_2$ | ... | $P_{m-1}$ | $K_m$ | $P_m$ |
- Sequence of $m+1$ pointers $P$ separated by different values $K$ ordered according to search key
- Pointer $P_{i-1}$ on the left value $K_i$ ($1 \le i \le m$) points to the subtree containing only data entries that are *less than* $K_i$
- Pointer $P_i$ on the right of value $K_i$ point to the subtree containing only data entries with values that are greater than or equal to $K_i$
Every node of the tree is one page, and the leaves only contain data entries.

We have two possibilities
#### ISAM - Indexed Sequential Access Method
It's useful *when the table is static*, with no addition or deletion. Every intermediate nodes have the same number of children (**fan-out**), which basically means that it's a balanced tree (every path from root to leaf has the same length -> Height of the tree is that length).
The *root* node may not have F childrens.

We'll have $F^H$ amount of leaves, with $F$ being the fan-out and $H$ being the numbers of levels. This creates a **huge** number of leaves

At every addition we pay a lot, because we will need to deal with overflow tables.

Searching costs $\log_F(N)$
#### $B^+$-trees
>The **rank** of the tree is the number of search key values that can be fit in a page. In every page we have space for d search keys and d+1 pointers

The dynamic version of ISAM. It's still balanced. The only difference is that the number of children for every node may not be the same: every node contains a number of data entries $m_i$  $\le d$ and $m_i \ge (d+1)/2$ 
This must be enforced. Leaves are then connected and linked together.
Basically, as fanout we use the *average* number of children, and we can assume the average will be $\displaystyle \frac{(d + d/2)}2 =  \frac{3d}4$


Whenever we want to create a B+ tree, and we want to have $B$ leaves, to keep occupancy rate at 66% we need to create $1.5B$ leaves!
### Hash-based

